{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow, your perceptron is learning for the first time !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This learning rule is an example of supervised training, in which the learning rule is provided\n",
    "with a set of examples of proper perecptron behavior: a collection of $(x,t)$ where $x$ is an input and $t$ is a the corresponding target output. As each input is applied to the network, the network output is compared\n",
    "to the target. **The learning rule then adjusts the weights and biases\n",
    "of the perceptron in order to move the perceptron output closer to the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test problem\n",
    "These are 3  input/target pairs for our test problem :\n",
    "$$x_1 = (1,2) \\,;\\, t_1 = 1 \\qquad x_2 = (-1,2) \\,;\\, t_2 = 0 \\qquad x_3 = (0,-1) \\,;\\, t_3 = 0$$\n",
    "\n",
    "The perceptron for this problem should have two-inputs and one output. To\n",
    "simplify our development of the learning rule, we will begin with a network\n",
    "without a bias so that we are looking for two weights $a_1,a_2$. Activation function is Heaviside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[];t=[]\n",
    "x.append(np.array([1,2])) ; t.append(1)\n",
    "x.append(np.array([-1,2])) ; t.append(0)\n",
    "x.append(np.array([0,-1])) ; t.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing Learning Rules\n",
    "We set the weight vector $w = (a_1,a_2)$ to the following randomly generated values: $w = (1.0, -0.8)$. \n",
    "\n",
    "Then we execute the perceptron with the first input $x_1$ : output $y_1$ is equal to $0 \\neq t_1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1.0,-0.8])\n",
    "y = sum(w*x[0])\n",
    "print(y)\n",
    "y = H(y)\n",
    "print(y)\n",
    "y == t[0] #test if output y_1 is equal to t_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule** : if $t=1$ and $y=0$ then $w_{new} := w_{old} + x$.\n",
    "\n",
    "Then we execute the perceptron with the second input $x_2$ and new weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w + x[0]\n",
    "y = H(sum(w*x[1]))\n",
    "y == t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule** : if $t=0$ and $y=1$ then $w_{new} := w_{old} - x$.\n",
    "\n",
    "Then we execute the perceptron with the second input $x_3$ and new weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - x[1]\n",
    "y = H(sum(w*x[2]))\n",
    "y == t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y - t[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the previous rule :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - x[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we check :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    y = H(sum(w*x[i]))\n",
    "    print(y == t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfying Learning Rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule can be extended to train the bias by noting that a bias is simply\n",
    "a weight whose input is always 1.\n",
    "\n",
    "#### Exercise :\n",
    "Write a program that applies all the rules given above with different weights at start. Check the result.\n",
    "\n",
    "Bonus : Represent with a 2d-graph the evolution of $w$ by plotting the corresponding linear classifyer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "w = np.array([-0.5,-0.9])\n",
    "for i in range(n):\n",
    "    y = H(sum(w*x[i]))\n",
    "    err = t[i]-y\n",
    "    w = w + err * x[i]\n",
    "for i in range(3):\n",
    "    y = H(sum(w*x[i]))\n",
    "    print(y == t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
