{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "h1 {\n",
    "  border: 1.5px solid #333;\n",
    "  padding: 8px 12px;\n",
    "  background-color:#a0cfc0;\n",
    "  position: static;\n",
    "}  \n",
    "h2 {\n",
    "  padding: 8px 12px;\n",
    "  background-color:#f0cfc0;\n",
    "  position: static;\n",
    "}   \n",
    "h3 {\n",
    "  padding: 4px 8px;\n",
    "  background-color:#f0cfc0;\n",
    "  position: static;\n",
    "}   \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'Apprentissage Automatique et la Règle d'Apprentissage du Perceptron\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons approfondir la notion d'apprentissage automatique en introduisant la règle d'apprentissage du perceptron. Précédemment, nous avons défini les notions de perceptron et de classifieur linéaire. Nous allons maintenant voir comment ces concepts s'inscrivent dans le cadre de l'apprentissage supervisé, en utilisant une règle d'apprentissage spécifique pour ajuster les poids du perceptron en fonction des erreurs commises.\n",
    "\n",
    "## Rappel : Perceptron et Classifieur Linéaire\n",
    "\n",
    "Le **perceptron** est un modèle de neurone artificiel simple qui effectue une classification binaire en séparant les données par une frontière linéaire. Il calcule une somme pondérée de ses entrées et applique une fonction d'activation pour produire une sortie.\n",
    "\n",
    "Le **classifieur linéaire** est un algorithme de classification qui fait des prédictions basées sur la combinaison linéaire des caractéristiques d'entrée. Il cherche à trouver un hyperplan qui sépare les données de différentes classes.\n",
    "\n",
    "## Introduction à l'Apprentissage Automatique\n",
    "\n",
    "L'**apprentissage automatique** (ou *machine learning*) est un domaine de l'intelligence artificielle qui permet aux systèmes informatiques d'apprendre et d'améliorer leurs performances à partir de données, sans être explicitement programmés pour chaque tâche. Il s'appuie sur des algorithmes capables de détecter des motifs et de faire des prédictions ou des décisions basées sur des données.\n",
    "\n",
    "## La Règle d'Apprentissage du Perceptron\n",
    "\n",
    "La **règle d'apprentissage du perceptron** est un algorithme d'apprentissage supervisé qui ajuste les poids du perceptron en fonction de l'erreur entre la sortie prédite et la sortie désirée. La règle d'apprentissage du perceptron utilise des étiquettes de classe connues pour guider le processus d'apprentissage. C'est un apprentissage _supervisé_.\n",
    "\n",
    "### Principe de la Règle d'Apprentissage du Perceptron\n",
    "\n",
    "Pour chaque exemple d'entraînement $(\\mathbf{x}, t)$, où $\\mathbf{x}$ est le vecteur d'entrée et $t$ la sortie cible (0 ou 1), le perceptron effectue les étapes suivantes :\n",
    "\n",
    "1. **Calcul de la sortie prédite** :\n",
    "   $$\n",
    "   y = H(\\mathbf{w} \\cdot \\mathbf{x})\n",
    "   $$\n",
    "   où \\(H\\) est la fonction de Heaviside (fonction seuil).\n",
    "\n",
    "2. **Mise à jour des poids** :\n",
    "   - Si \\(t = 1\\) et \\(y = 0\\), alors :\n",
    "     $$\n",
    "     \\mathbf{w}_{\\text{nouveau}} = \\mathbf{w}_{\\text{ancien}} + \\mathbf{x}\n",
    "     $$\n",
    "   - Si \\(t = 0\\) et \\(y = 1\\), alors :\n",
    "     $$\n",
    "     \\mathbf{w}_{\\text{nouveau}} = \\mathbf{w}_{\\text{ancien}} - \\mathbf{x}\n",
    "     $$\n",
    "   - Sinon, les poids restent inchangés.\n",
    "\n",
    "### Exemple d'Application\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette règle d'apprentissage est un exemple d'apprentissage supervisé. On donne une collection de $(x,t)$ où $x$ est une entrée et $t$ la sortie attentue \"target\". A chaque calcul, on compare la sortie effective avec la sortie attendue. \n",
    "\n",
    "Ensuite, la règle ajuste les paramètres de telle sorte que le perceptron évolue pour être plus proche de la sortie attendue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction Heavyside\n",
    "def H(y):\n",
    "    if y<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple de problème\n",
    "Il y a 3  paire d'input/target :\n",
    "$$x_1 = (1,2) \\,;\\, t_1 = 1 \\qquad x_2 = (-1,2) \\,;\\, t_2 = 0 \\qquad x_3 = (0,-1) \\,;\\, t_3 = 0$$\n",
    "\n",
    "Le perceptron doit être défini de $\\mathbb{R}^2$ dans $\\mathbb{R}$ soit 2 entrées et 1 sortie. Pour simplifier ici, on ne cherche pas de biais donc on cherche deux poids $a_1,a_2$. La fonction d'activation choisie est Heaviside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[];t=[]\n",
    "x.append(np.array([1,2])) ; t.append(...)\n",
    "x.append(np.array([-1,2])) ; t.append(...)\n",
    "x.append(np.array([0,-1])) ; t.append(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Règles d'apprentissage pas à pas\n",
    "On prend un vecteur poids $w = (a_1,a_2)$ avec des valeurs arbitraires, par exemple : $w = (1.0, -0.8)$. \n",
    "\n",
    "Ensuite on exécute le preceptron avec l'entrée $x_1$ : la sortie $y_1$ est égale à $0 \\neq t_1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1.0,-0.8])\n",
    "y = sum(w*x[0])\n",
    "print(y)\n",
    "y = H(y)\n",
    "print(y)\n",
    "y == t[0] #test if output y_1 is equal to t_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Règle** : si $t=1$ et $y=0$ alors $w_{new} := w_{old} + x$.\n",
    "\n",
    "Alors on exécute le perceptron avec l'entrée $x_2$ et les nouveaux poids :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ...\n",
    "y = H(sum(w*x[1]))\n",
    "y == t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Règle** : si $t=0$ et $y=1$ alors $w_{new} := w_{old} - x$.\n",
    "\n",
    "Alors on exécute le perceptron avec l'entrée $x_3$ et les nouveaux poids :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w ...\n",
    "y = H(sum(w*x[2]))\n",
    "y == t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y - t[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la règle précédente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on vérifie si la sortie $y$ est égale à la cible $t$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    y = H(sum(w*x[i]))\n",
    "    print(y == t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unifier les règles d'apprentissage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette règle peut être étendue pour entrainer un biais. \n",
    "\n",
    "#### Exercice :\n",
    "Ecrire un programme qui applique toutes les règles ci-dessus avec différents poids au départ. Vérifier les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "w = np.array([-0.5,-0.9])\n",
    "for i in range(n):\n",
    "    ...\n",
    "for i in range(3):\n",
    "    y = H(sum(w*x[i]))\n",
    "    print(y == t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des Données d'Entrée et des Sorties Cibles\n",
    "\n",
    "Nous réutilisons le jeu de données suivant :\n",
    "\n",
    "- **Entrées** :\n",
    "  $$\n",
    "  \\mathbf{x}_1 = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix}, \\quad \\mathbf{x}_2 = \\begin{bmatrix}-1 \\\\ 2\\end{bmatrix}, \\quad \\mathbf{x}_3 = \\begin{bmatrix}0 \\\\ -1\\end{bmatrix}\n",
    "  $$\n",
    "- **Sorties cibles** :\n",
    "  $$\n",
    "  t_1 = 1, \\quad t_2 = 0, \\quad t_3 = 0\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'entrée\n",
    "X = []\n",
    "X.append(np.array([1, 2]))\n",
    "X.append(np.array([-1, 2]))\n",
    "X.append(np.array([0, -1]))\n",
    "\n",
    "# Sorties cibles\n",
    "T = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'Activation de Heaviside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(v):\n",
    "    return 1 if v >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation des Poids\n",
    "Nous initialisons les poids du perceptron avec des valeurs aléatoires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1.0, -0.8])\n",
    "print(\"Poids initiaux :\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application de la Règle d'Apprentissage du Perceptron\n",
    "\n",
    "Nous allons appliquer la règle d'apprentissage du perceptron pour chaque exemple d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'exemples\n",
    "n = len(X)\n",
    "\n",
    "# Taux d'apprentissage\n",
    "eta = 1  # Pour simplifier, nous utilisons un taux d'apprentissage de 1\n",
    "\n",
    "# Phase d'apprentissage\n",
    "for i in range(n):\n",
    "    x_i = ...\n",
    "    t_i = ...\n",
    "    y_i = ...\n",
    "    error = ...\n",
    "    w = w + eta * ... * ...\n",
    "    print(f\"Après l'exemple {i+1}, poids mis à jour : {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification des Résultats\n",
    "\n",
    "Nous vérifions maintenant si le perceptron classifie correctement tous les exemples après l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase de test\n",
    "for i in range(n):\n",
    "    x_i = ...\n",
    "    t_i = ...\n",
    "    y_i = ...\n",
    "    print(f\"Exemple {i+1} : Sortie prédite = {y_i}, Sortie réelle = {t_i}, Correct = {y_i == t_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation de la Frontière de Décision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un maillage pour la visualisation\n",
    "xx, yy = np.meshgrid(np.linspace(-2, 4, 200), np.linspace(-2, 4, 200))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = np.array([H(np.dot(w, point)) for point in grid])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Visualisation\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter([X[i][0] for i in range(n)], [X[i][1] for i in range(n)], c=T, edgecolors='k')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Frontière de décision du perceptron après apprentissage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La figure ci-dessus montre la frontière de décision du perceptron après apprentissage.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "Écrivez un programme qui applique les règles d'apprentissage données ci-dessus avec différents poids initiaux. Vérifiez si le perceptron parvient à classer correctement les exemples après l'apprentissage.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'entrée (inchangées)\n",
    "X = []\n",
    "X.append(np.array([1, 2]))\n",
    "X.append(np.array([-1, 2]))\n",
    "X.append(np.array([0, -1]))\n",
    "\n",
    "# Sorties cibles (inchangées)\n",
    "T = [1, 0, 0]\n",
    "\n",
    "# Fonction d'activation de Heaviside (inchangée)\n",
    "def H(v):\n",
    "    return 1 if v >= 0 else 0\n",
    "\n",
    "# Poids initiaux différents\n",
    "w = np.array([-0.5, -0.9])\n",
    "print(\"Poids initiaux :\", w)\n",
    "\n",
    "# Nombre d'exemples\n",
    "n = len(X)\n",
    "\n",
    "# Phase d'apprentissage\n",
    "for epoch in range(10):  # Nombre d'époques d'apprentissage\n",
    "    print(f\"\\nÉpoque {epoch+1}\")\n",
    "    for i in range(n):\n",
    "        x_i = X[i]\n",
    "        t_i = T[i]\n",
    "        y_i = H(np.dot(w, x_i))\n",
    "        error = t_i - y_i\n",
    "        w = w + error * x_i\n",
    "        print(f\"Exemple {i+1}, Erreur = {error}, Poids mis à jour : {w}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification des Résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase de test\n",
    "print(\"\\nPhase de test après apprentissage\")\n",
    "for i in range(n):\n",
    "    x_i = X[i]\n",
    "    t_i = T[i]\n",
    "    y_i = H(np.dot(w, x_i))\n",
    "    print(f\"Exemple {i+1} : Sortie prédite = {y_i}, Sortie réelle = {t_i}, Correct = {y_i == t_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus : Visualisation de l'Évolution des Poids\n",
    "\n",
    "Nous pouvons représenter graphiquement l'évolution de la frontière de décision du perceptron au cours des itérations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réinitialisation des poids\n",
    "w = np.array([-0.5, -0.9])\n",
    "\n",
    "# Stockage des poids pour la visualisation\n",
    "weights_history = [w.copy()]\n",
    "\n",
    "# Phase d'apprentissage avec stockage des poids\n",
    "for epoch in range(10):\n",
    "    for i in range(n):\n",
    "        x_i = X[i]\n",
    "        t_i = T[i]\n",
    "        y_i = H(np.dot(w, x_i))\n",
    "        error = t_i - y_i\n",
    "        w = w + error * x_i\n",
    "        weights_history.append(w.copy())\n",
    "\n",
    "# Visualisation de l'évolution de la frontière de décision\n",
    "plt.figure(figsize=(10, 6))\n",
    "for idx, w in enumerate(weights_history):\n",
    "    if idx % 2 == 0:  # Pour éviter un trop grand nombre de courbes\n",
    "        # Calcul de la frontière de décision\n",
    "        x_vals = np.linspace(-2, 4, 100)\n",
    "        y_vals = -(w[0]/w[1]) * x_vals\n",
    "        plt.plot(x_vals, y_vals, label=f'Itération {idx}')\n",
    "\n",
    "# Données\n",
    "plt.scatter([X[i][0] for i in range(n)], [X[i][1] for i in range(n)], c=T, edgecolors='k')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title(\"Évolution de la frontière de décision du perceptron\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La figure ci-dessus montre l'évolution de la frontière de décision du perceptron au cours des itérations.*\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "La règle d'apprentissage du perceptron est un algorithme supervisé simple mais puissant pour l'ajustement des poids dans un réseau neuronal. Elle illustre comment un modèle peut apprendre à partir de données étiquetées en minimisant l'erreur entre la sortie prédite et la sortie désirée. Bien que le perceptron ne puisse résoudre que des problèmes linéairement séparables, il constitue une base importante pour comprendre des réseaux neuronaux plus complexes et des algorithmes d'apprentissage plus avancés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
